# Model definition:
glm_vif3<- update(glm_vif2, . ~ . - Inflight_wifi_service, family = "binomial")
summary(glm_vif3)
vif_values <- VIF(glm_vif3)
vif_values
r2_vif<- 1 - (summary(glm_vif3)$deviance/summary(glm_vif3)$null.deviance)
r2_vif
1/(1-r2_vif)
# Convert data to matrix format (if not already)
X_train <- as.matrix(X_train)
y_train <- as.numeric(y_train)
# Fit lasso regression model with cross-validation
lasso_model <- cv.glmnet(X_train, y_train, alpha = 1, family = "binomial")
knitr::opts_chunk$set(echo = TRUE)
# import libraries
library(tidyverse)
library(corrplot)
library(ggplot2)
library(gridExtra)
library(correlation)
library(reshape)
library(reshape2)
library(tidyverse) # for data manipulation
library(ggplot2) # for plotting
library(gridExtra) # for grid.arrange
library(regclass) # for VIF package
library(MLmetrics) # to create confusion matrix
library(pROC) # for ROC Curve
library(e1071) # for Naive Bayes Classifier
library(class)
library(caret)
library(glmnet) # for Lasso Regression
data_train = read.csv("train.csv")
data_test = read.csv("test.csv")
# merge train and test data
data = rbind(data_train, data_test)
attach(data)
summary(data)
prop.table(table(data$satisfaction))
table(data$Gender)
table(data$Customer.Type)
table(data$Type.of.Travel)
table(data$Class)
table(data$satisfaction)
# replace dots with underscores in column names
names(data) = gsub("\\.", "_", names(data))
# drop X and id column
data = data %>% select(-X, -id)
names(data)
# convert categorical features to factor
data$Gender = as.factor(data$Gender)
data$Customer_Type = as.factor(data$Customer_Type)
data$Type_of_Travel = as.factor(data$Type_of_Travel)
data$Class = as.factor(data$Class)
data$satisfaction = as.factor(data$satisfaction)
data$Arrival_Delay_in_Minutes <- as.numeric(data$Arrival_Delay_in_Minutes)
ratings_fts_names = c("Inflight_wifi_service", "Departure_Arrival_time_convenient",
"Ease_of_Online_booking", "Gate_location", "Food_and_drink", "Online_boarding",
"Seat_comfort", "Inflight_entertainment", "On_board_service", "Leg_room_service",
"Baggage_handling", "Checkin_service", "Inflight_service", "Cleanliness", "On_board_service")
for (col in ratings_fts_names) {
data[[col]] = as.factor(data[[col]])
}
# list features with na values
prop.table(colSums(is.na(data)))
# Arrival_Delay_in_Minutes has na values, proportion of na values
prop.table(table(is.na(data$Arrival_Delay_in_Minutes)))
# drop na values in Arrival_Delay_in_Minutes
data = data[!is.na(data$Arrival_Delay_in_Minutes),]
any(is.na(data))
# plot boxplot of each numeric variable excluding ratings features
plots = list()
for (col in names(data)[sapply(data, is.numeric)]) {
if (col %in% ratings_fts_names) {
next
}
plot = ggplot(data, aes(x = .data[[col]])) +
geom_boxplot() +
labs(title = col, x = col, y = "Count")
plots[[col]] = plot
}
grid.arrange(grobs = plots, ncol = 2)
# plot distribution of categorical variables
plots = list()
for (col in names(data)[sapply(data, is.factor)]) {
if (col %in% ratings_fts_names) {
next
}
plot = ggplot(data, aes(x = .data[[col]], fill = .data[[col]])) +
geom_bar() +
labs(title = paste("Histogram of", col), x = col, y = "Count") +
guides(fill = FALSE)
plots[[col]] = plot
}
grid.arrange(grobs = plots, ncol = 2)
# plot distribution of ratings features
plots = list()
my_palette <- c("#1f78b4", "#33a02c", "#e31a1c", "#ff7f00", "#6a3d9a", "#b15928")
for (col in names(data)[sapply(data, is.factor)]) {
if (!col %in% ratings_fts_names) {
next
}
plot <- ggplot(data, aes(x = .data[[col]], fill = factor(.data[[col]]))) +
geom_bar() +
geom_text(stat = 'count', aes(label = after_stat(count))) +
labs(title = paste("Histogram of ", col), x = col, y = "Count") +
scale_fill_manual(values = my_palette) +
guides(fill = FALSE)
plots[[col]] <- plot
}
grid.arrange(grobs = plots, ncol = 3)
# compute the mean value of all the ratings
ratings_data = data[, c(ratings_fts_names)]
ratings_data <- apply(ratings_data, 2, as.numeric)
ratings_mean = colMeans(ratings_data)
ratings_mean
# plot distribution and density of numeric variables excluding ratings features
plots = list()
for (col in names(data)[sapply(data, is.numeric)]) {
if (col %in% ratings_fts_names) {
next
}
plot = ggplot(data, aes(x = .data[[col]])) +
geom_histogram(aes(y = after_stat(density)), bins = 30, alpha = 0.5) +
geom_density(alpha = 0.2, fill = "red") +
labs(title = paste("Histogram of", col), x = col, y = "Count")
plots[[col]] = plot
}
grid.arrange(grobs = plots, ncol = 2)
# plots categorical variables vs satisfaction
plots = list()
for (col in names(data)[sapply(data, is.factor)]) {
if (col == "satisfaction" || col %in% ratings_fts_names) {
next
}
plot = ggplot(data, aes(x = satisfaction, fill = .data[[col]])) +
theme_minimal() +
geom_bar(position = "dodge") +
labs(title = paste("Histogram of Satisfaction by", col), x = "Satisfaction", y = "Count")
plots[[col]] = plot
}
grid.arrange(grobs = plots, ncol = 2)
# calculate the mean of the ratings of unsatisfied/neutral consumers
ratings_data = data[data$satisfaction == "neutral or dissatisfied", c(ratings_fts_names)]
ratings_data <- apply(ratings_data, 2, as.numeric)
ratings_mean = colMeans(ratings_data)
ratings_mean
# calculate the mean of the ratings of unsatisfied/neutral consumers
ratings_data = data[data$satisfaction == "satisfied", c(ratings_fts_names)]
ratings_data <- apply(ratings_data, 2, as.numeric)
ratings_mean = colMeans(ratings_data)
ratings_mean
# plots ratings features vs satisfaction
plots = list()
for (col in names(data)[sapply(data, is.factor)]) {
if (!col %in% ratings_fts_names) {
next
}
plot = ggplot(data, aes(x = .data[[col]], fill = satisfaction)) +
theme_minimal() +
geom_bar(position = "dodge") +
labs(title = paste("Histogram of Satisfaction by", col), x = "Satisfaction", y = "Count")
plots[[col]] = plot
}
grid.arrange(grobs = plots, ncol = 2)
# plots numeric variables vs satisfaction excluding ratings features with histograms of different colors for each satisfaction level
plots = list()
for (col in names(data)[sapply(data, is.numeric)]) {
if (col %in% ratings_fts_names) {
next
}
plot = ggplot(data, aes(x = .data[[col]], fill = satisfaction, group = satisfaction)) +
theme_minimal() +
geom_histogram(alpha = 0.5, bins = 30) +
labs(title = paste("Histogram of", col), x = col, y = "Count")
plots[[col]] = plot
}
grid.arrange(grobs = plots, ncol = 2)
gender_map = c("Male" = 0, "Female" = 1)
data$Gender = gender_map[as.numeric(data$Gender)]
customer_type_map = c("Loyal Customer" = 0, "disloyal Customer" = 1)
data$Customer_Type = customer_type_map[as.numeric(data$Customer_Type)]
type_of_travel_map = c("Personal Travel" = 0, "Business travel" = 1)
data$Type_of_Travel = type_of_travel_map[as.numeric(data$Type_of_Travel)]
class_map = c("Business" = 0, "Eco" = 1, "Eco Plus" = 2)
data$Class = class_map[as.numeric(data$Class)]
satisfaction_map = c("neutral or dissatisfied" = 0, "satisfied" = 1)
data$satisfaction = satisfaction_map[as.numeric(data$satisfaction)]
for (col in ratings_fts_names) {
data[[col]] <- as.numeric(data[[col]])
}
set.seed(123)
train_index = sample(1:nrow(data), 0.8*nrow(data))
# 80% of data is used for training
train_data = data[train_index,]
# 20% of data is used for testing
test_data = data[-train_index,]
# Seperate y_train and y_test for further use
X_train = as.matrix(train_data %>% select(-satisfaction))
y_train = train_data$satisfaction
X_test = as.matrix(test_data %>% select(-satisfaction))
y_test = test_data$satisfaction
# Number of samples in train data
train_rows <- nrow(train_data)
print(train_rows)
# Number of samples in test data
test_rows <- nrow(test_data)
print(test_rows)
# Proportion of satisfied and unsatisfied customers for train data
prop.table(table(y_train))
# Proportion of satisfied and unsatisfied customers for test data
prop.table(table(y_test))
# Model definition with all features:
glm_full<- glm(data = train_data,satisfaction ~ .,
family = "binomial")
# summary of full model
summary(glm_full)
r2<- 1 - (summary(glm_full)$deviance/summary(glm_full)$null.deviance)
r2
1/(1-r2)
# VIF Iteration 0
# The process is done iteratively where we delete one variable at time
vif_values <- VIF(glm_full)
# Create a data frame with variable names and their corresponding VIF values
vif_df <- data.frame(Variable = names(vif_values), VIF = vif_values,row.names = NULL)
# Sort the data frame in decreasing order of VIF values
sorted_df <- vif_df[order(-vif_df$VIF), ]
rownames(sorted_df) <- NULL
# Print the sorted data frame
print(sorted_df)
# VIF Iteration 1
# The process is done iteratively where we delete one variable at time
# Model definition:
glm_vif1<- glm(data = train_data,
satisfaction ~ .-Arrival_Delay_in_Minutes,
family = "binomial")
vif_values <- VIF(glm_vif1)
# Create a data frame with variable names and their corresponding VIF values
vif_df <- data.frame(Variable = names(vif_values), VIF = vif_values,row.names = NULL)
# Sort the data frame in decreasing order of VIF values
sorted_df <- vif_df[order(-vif_df$VIF), ]
rownames(sorted_df) <- NULL
# Print the sorted data frame
print(sorted_df)
# VIF Iteration 2
# The process is done iteratively where we delete one variable at time
# Model definition:
glm_vif2<- glm(data = train_data,
satisfaction ~ .
-Arrival_Delay_in_Minutes
-Inflight_entertainment,
family = "binomial")
vif_values <- VIF(glm_vif2)
# Create a data frame with variable names and their corresponding VIF values
vif_df <- data.frame(Variable = names(vif_values), VIF = vif_values,row.names = NULL)
# Sort the data frame in decreasing order of VIF values
sorted_df <- vif_df[order(-vif_df$VIF), ]
rownames(sorted_df) <- NULL
# Print the sorted data frame
print(sorted_df)
# VIF Iteration 3
# The process is done iteratively where we delete one variable at time
# Model definition:
glm_vif3<- glm(data = train_data,
satisfaction ~ .
-Arrival_Delay_in_Minutes
-Inflight_entertainment
-Ease_of_Online_booking	,
family = "binomial")
vif_values <- VIF(glm_vif3)
# Create a data frame with variable names and their corresponding VIF values
vif_df <- data.frame(Variable = names(vif_values), VIF = vif_values,row.names = NULL)
# Sort the data frame in decreasing order of VIF values
sorted_df <- vif_df[order(-vif_df$VIF), ]
rownames(sorted_df) <- NULL
# Print the sorted data frame
print(sorted_df)
# VIF Iteration 4
# The process is done iteratively where we delete one variable at time
# Model definition:
glm_vif4<- glm(data = train_data,
satisfaction ~ .
-Arrival_Delay_in_Minutes
-Inflight_entertainment
-Ease_of_Online_booking
-Cleanliness	,
family = "binomial")
vif_values <- VIF(glm_vif4)
# Create a data frame with variable names and their corresponding VIF values
vif_df <- data.frame(Variable = names(vif_values), VIF = vif_values,row.names = NULL)
# Sort the data frame in decreasing order of VIF values
sorted_df <- vif_df[order(-vif_df$VIF), ]
rownames(sorted_df) <- NULL
# Print the sorted data frame
print(sorted_df)
glm_reduced<- glm(data = train_data,
satisfaction ~ .
-Arrival_Delay_in_Minutes
-Inflight_entertainment
-Ease_of_Online_booking
-Cleanliness	,
family = "binomial")
# Observation of the model summary:
summary(glm_reduced)
# Drop Flight_Distance and Gate_location from model.
glm_backward<- glm(data = train_data,
satisfaction ~ .
-Arrival_Delay_in_Minutes
-Inflight_entertainment
-Ease_of_Online_booking
-Cleanliness
-Flight_Distance
-Gate_location,
family = "binomial")
summary(glm_backward)
r2<- 1 - (summary(glm_backward)$deviance/summary(glm_backward)$null.deviance)
r2
# We look for the best value for lambda
# We use cross validation glmnet
glm_lasso <- cv.glmnet(X_train, as.factor(y_train),
alpha = 0, family = "binomial", type.measure = "class")
plot(glm_lasso)
# We identify th best lambda value
best_lambda <- glm_lasso$lambda.min
best_lambda
# Full model
# Computing the predictions with the model on the test set:
pred_glm_full<- predict(glm_full, data.frame(X_test), type = "response")
# Backward elimination selection
# Computing the predictions with the model on the test set:
pred_glm_backward<- predict(glm_backward, data.frame(X_test), type = "response")
# Lasso regresssion
# Computing the predictions with the model on the test set:
pred_glm_lasso<- predict(glm_lasso, X_test, type= "response", s = best_lambda)
par(pty="s")
roc(y_test,pred_glm_full,plot=TRUE, legacy.axes=TRUE, percent=TRUE,
xlab="False Positive Percentage", ylab="True Positive Percentage",
col="blue", lwd=4,
print.auc=TRUE, print.auc.y=60, print.auc.x=30,
quiet = TRUE)
plot.roc(y_test,pred_glm_backward,add=TRUE, legacy.axes=TRUE, percent=TRUE,
xlab="False Positive Percentage", ylab="True Positive Percentage",
col="red", lwd=4,
print.auc=TRUE, print.auc.y=50, print.auc.x=30,
quiet = TRUE)
plot.roc(y_test,pred_glm_lasso,add=TRUE, legacy.axes=TRUE, percent=TRUE,
xlab="False Positive Percentage", ylab="True Positive Percentage",
col="green", lwd=4,
print.auc=TRUE, print.auc.y=40, print.auc.x=30,
quiet = TRUE)
legend("bottomright",
legend=c("glm_full","glm_backward","glm_lasso"),
col=c("blue","red","green"),
lwd=4)
# This function will return evaluation metrics
calculate_evaluation_metrics <- function(thresholds, output_list, y_test) {
# Create an empty data frame to store the results
results_df <- data.frame(
Threshold = numeric(length(thresholds)),
Accuracy = numeric(length(thresholds)),
F1_Score = numeric(length(thresholds)),
Precision = numeric(length(thresholds)),
Recall = numeric(length(thresholds))
)
# Calculate evaluation metrics for each threshold
# Store the results in the data frame
for (i in 1:length(thresholds)) {
threshold <- thresholds[i]
pred_output <- output_list[[as.character(threshold)]]
results_df[i, "Threshold"] <- threshold
results_df[i, "Accuracy"] <- Accuracy(y_pred = pred_output, y_true = y_test)
results_df[i, "F1_Score"] <- F1_Score(y_pred = pred_output, y_true = y_test)
results_df[i, "Precision"] <- Precision(y_pred = pred_output, y_true = y_test)
results_df[i, "Recall"] <- Recall(y_pred = pred_output, y_true = y_test)
}
# Format the floating-point numbers with two decimal places
results_df$Accuracy <- round(results_df$Accuracy, 4)
results_df$F1_Score <- round(results_df$F1_Score, 4)
results_df$Precision <- round(results_df$Precision, 4)
results_df$Recall <- round(results_df$Recall, 4)
return(results_df)
}
evaluate_on_thresholds <- function(predictions,y_test, thresholds) {
# Converting the prediction in {0,1} according to the chosen threshold:
output_list <- list()
for (threshold in thresholds) {
output <- ifelse(predictions > threshold, 1, 0)
output_list[[as.character(threshold)]] <- output
}
# Access the outputs using the threshold values as keys
#output_list$`0.4`
#output_list$`0.5`
#output_list$`0.6`
#output_list$`0.7`
# Calculate evaluation metrics
results <- calculate_evaluation_metrics(thresholds, output_list, y_test)
# Print the results as a table in R Markdown
knitr::kable(results, align = "c")
}
thresholds <- c(0.4, 0.5, 0.6, 0.7)
evaluate_on_thresholds(pred_glm_full, y_test, thresholds)
thresholds <- c(0.4, 0.5, 0.6, 0.7)
evaluate_on_thresholds(pred_glm_backward, y_test, thresholds)
thresholds <- c(0.4, 0.5, 0.6, 0.7)
evaluate_on_thresholds(pred_glm_lasso, y_test, thresholds)
nb.fit <- naiveBayes(data = data.frame(X_train),
y_train ~ .)
# Make predictions on the test data
pred_naive_bayes <- predict(nb.fit, newdata = X_test)
# Evaluate accuracy of classifier
mean(pred_naive_bayes == y_test)
# Best Subset Selection
# The regsubsets() function (part of the leaps library)
# performs best subset selection by identifying the best
# model that contains a given number of predictors,
# where best is quantified using bic
n <- dim(X_train)[1]
regfit.full <- regsubsets(y_train~.,data=data.frame(X_train),nvmax=n)
reg.summary <- summary(regfit.full)
# Plotting BIC
# BIC with its smallest value
plot(reg.summary$bic,xlab="Number of Variables",ylab="BIC",type='l')
min <- which.min(reg.summary$bic)
points(10,reg.summary$bic[10],col="red",cex=2,pch=20)
# choose 10 variable model
best_model <- coef(regfit.full, id = 10)
abs_coefficients <- abs(best_model)
sorted_variables <- names(sort(abs_coefficients, decreasing = TRUE))
column_names <- sorted_variables[-1]
new_X_train <- X_train[, column_names, drop = FALSE]
new_X_test <- X_test[, column_names, drop = FALSE]
nb.fit <- naiveBayes(data = data.frame(new_X_train),
y_train ~ .)
# Make predictions on the test data
pred_naive_bayes <- predict(nb.fit, newdata = new_X_test)
# Evaluate accuracy
mean(pred_naive_bayes == y_test)
# Function for feature scaling
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
# We normalize the columns
train_scaled <- as.data.frame(lapply(train_data, min_max_norm))
test_scaled<- as.data.frame(lapply(test_data, min_max_norm))
# KNN with K-fold cross validation
# Define a range of K values
k_values <- 1:10
# Perform cross-validation and calculate error rates
error_rates <- sapply(k_values, function(k) {
set.seed(123)  # For reproducibility
model <- train(as.factor(satisfaction)~., data = train_scaled,
method = "knn",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = data.frame(k = k))
1 - model$results$Accuracy
})
# Plot the Error Rates
plot(k_values, error_rates, type = "b", pch = 16, xlab = "K Value", ylab = "Error Rate",
main = "KNN: Error Rate vs. K Value")
# find the k giving minimum error rate
k_min <- which.min(error_rates)
k_min
# make predictions with k = k_min
pred_knn<- knn(train_scaled[,-23], test_scaled[,-23],
cl = train_scaled$satisfaction,
k = k_min)
# Create a function for confusion matrix and other metrics
draw_confusion_matrix <- function(cm) {
layout(matrix(c(1,1,2)))
par(mar=c(2,2,2,2))
plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
title('CONFUSION MATRIX', cex.main=2)
# create the matrix
rect(150, 430, 240, 370, col='#3F97D0')
text(195, 435, 'Unsatisfied', cex=1.2)
rect(250, 430, 340, 370, col='#F7AD50')
text(295, 435, 'Satisfied', cex=1.2)
text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
text(245, 450, 'Actual', cex=1.3, font=2)
rect(150, 305, 240, 365, col='#F7AD50')
rect(250, 305, 340, 365, col='#3F97D0')
text(140, 400, 'Unsatisfied', cex=1.2, srt=90)
text(140, 335, 'Satisfied', cex=1.2, srt=90)
# add in the cm results
res <- as.numeric(cm$table)
text(195, 400, res[1], cex=1.6, font=2, col='white')
text(195, 335, res[2], cex=1.6, font=2, col='white')
text(295, 400, res[3], cex=1.6, font=2, col='white')
text(295, 335, res[4], cex=1.6, font=2, col='white')
# add in the specifics
plot(c(100, 0), c(50, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
text(30, 40, names(cm$byClass[5]), cex=1.2, font=2)
text(30, 30, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
text(50, 40, names(cm$byClass[7]), cex=1.2, font=2)
text(50, 30, round(as.numeric(cm$byClass[7]), 3), cex=1.2)
text(70, 40, names(cm$byClass[6]), cex=1.2, font=2)
text(70, 30, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
}
# Confusion matrix for glm_full_model
# Use best threshold for prediction (0 or 1)
Threshold <- 0.6
pred_glm_full_factor <- as.factor(ifelse(pred_glm_full >= Threshold , 1,0))
conf_matrix_glm <- confusionMatrix(data = pred_glm_full_factor,
reference = as.factor(y_test))
draw_confusion_matrix(conf_matrix_glm)
# Confusion matrix for Naive Bayes
conf_matrix_naive <- confusionMatrix(data = pred_naive_bayes,
reference = as.factor(y_test))
draw_confusion_matrix(conf_matrix_naive)
# Confusion matrix for KNN
conf_matrix_knn <- confusionMatrix(data = pred_knn, reference = as.factor(y_test))
draw_confusion_matrix(conf_matrix_knn)
