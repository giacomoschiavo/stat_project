---
title: "EDA"
author: "SÃ¼leyman Erim, Giacomo Schiavo, Mattia Varagnolo"
date: "`r Sys.Date()`"
output: pdf_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction to data

This section introduces the purpose of the exploratory data analysis
(EDA) and sets up the necessary libraries and data files.

```{r message=FALSE}
# import libraries
library(tidyverse)
library(corrplot)
library(ggplot2)
library(gridExtra)
library(correlation)
library(reshape)
library(reshape2)
library(corrr)
library(viridis)
```


```{r message=FALSE}
data_train = read.csv("train.csv")
data_test = read.csv("test.csv")

# merge train and test data
data = rbind(data_train, data_test)
attach(data)
```


# Introduction
In this project, we will develop a predictive model to determine whether a passenger will be satisfied or dissatisfied with the services offered by an airline company. The dataset used for this project is a survey on airline passenger satisfaction, which contains information about passengers' demographics, travel preferences, and satisfaction with various aspects of their flights.

The dataset: https://www.kaggle.com/datasets/teejmahal20/airline-passenger-satisfaction


Here are the variables in the dataset:

- Gender: Gender of the passengers (Female, Male)
- Customer Type: The customer type (Loyal customer, disloyal customer)
- Age: The actual age of the passengers
- Type of Travel: Purpose of the flight of the passengers (Personal Travel, Business Travel)
- Class: Travel class in the plane of the passengers (Business, Eco, Eco Plus)
- Flight distance: The flight distance of this journey
- Inflight wifi service: Satisfaction level of the inflight wifi service (0: Not Applicable; 1-5)
- Departure/Arrival time convenient: Satisfaction level of Departure/Arrival time convenient
- Ease of Online booking: Satisfaction level of online booking
- Gate location: Satisfaction level of Gate location
- Food and drink: Satisfaction level of Food and drink
- Online boarding: Satisfaction level of online boarding
- Seat comfort: Satisfaction level of Seat comfort
- Inflight entertainment: Satisfaction level of inflight entertainment
- On-board service: Satisfaction level of On-board service
- Leg room service: Satisfaction level of Leg room service
- Baggage handling: Satisfaction level of baggage handling
- Check-in service: Satisfaction level of Check-in service
- Inflight service: Satisfaction level of inflight service
- Cleanliness: Satisfaction level of Cleanliness
- Departure Delay in Minutes: Minutes delayed when departure
- Arrival Delay in Minutes: Minutes delayed when Arrival
- Satisfaction: Airline satisfaction level (Satisfaction, neutral or dissatisfaction)


The objective of our report is to predict passenger satisfaction with airline services based on the provided dataset, which includes various demographic and satisfaction-related variables such as gender, age, travel type, flight class, and satisfaction levels with different aspects of the journey. 
The dataset represents a survey on airline passenger satisfaction and will be used to develop a predictive model to determine whether passengers will be satisfied or dissatisfied with the airline services.

Now we're going to get a summary of all the features in our dataset:
```{r}
summary(data)
```

From the summary, it is evident that many features represent ratings on the services provided by the airline agency, and these ratings range from 0 to 5. Additionally, we noticed that the "Arrival Delay in Minutes" feature contains some missing values (NA).

Next, we will examine the distribution of all nominal features. Specifically, we have categorical data for Gender, Customer Type, Type of Travel, and Class, while all the rating features are ordinal.

```{r}
table(data$Gender)
```
The "Gender" feature appears to be well-balanced, meaning that it has an approximately equal number of occurrences for each category, likely male and female. This balance can be beneficial for modeling as it prevents any significant bias towards a particular gender in the analysis and predictions.

```{r}
table(data$Customer.Type)
```
The "Customer Type" feature contains only two values, "disloyal customer" and "loyal customer." The distribution of values is imbalanced, with one category potentially having significantly more occurrences than the other.
```{r}
table(data$Type.of.Travel)
```
The "Type of Travel" feature consists of only two values: "personal travel" and "business travel." The distribution of values is imbalanced, with "business travel" occurring twice as much as "personal travel."

```{r}
table(data$Class)
```
The "Class" feature contains three values: "business," "eco plus," and "eco." The distribution of values is imbalanced. "Business" and "eco" classes appear to be relatively balanced, while "eco plus" is significantly underrepresented compared to the other two classes.

```{r}
table(data$satisfaction)
```
The "satisfaction" feature, which serves as our target variable, is an important aspect of the analysis. The values for this feature are not perfectly balanced, meaning that there is an unequal distribution of satisfied and dissatisfied passengers in the dataset.

# Data preprocessing

In this section of data preprocessing, several steps are performed to prepare the dataset for further analysis and modeling. The specific actions taken include:

1. Renaming columns: the names of the features (columns) are modified to improve their clarity and usability. 

2. Dropping unnecessary columns: two columns, "X" and "id," are removed from the dataset. The "X" column likely represents the index of the row, which does not carry any meaningful information for analysis. The "id" column is presumed to be an unknown indexing number, which may not contribute to the predictive modeling process.

3. Converting categorical variables to factors: categorical variables, such as "Gender", "Customer Type", "Type of Travel" and "Class" are converted into factors. Converting categorical variables into factors is a common practice in R to represent these variables as distinct levels, allowing for better handling and analysis in statistical models.

By performing these data preprocessing steps, the dataset is cleaned and transformed into a more suitable format for the subsequent analysis, making it easier to build a predictive model for passenger satisfaction.

```{r}
# replace dots with underscores in column names
names(data) = gsub("\\.", "_", names(data))
# drop X and id column
data = data %>% select(-X, -id)
names(data)
```

```{r}
# convert categorical features to factor
data$Gender = factor(data$Gender, levels = c("Male", "Female"))
data$Customer_Type = factor(data$Customer_Type, levels = c("Loyal Customer", "disloyal Customer"))
data$Type_of_Travel = factor(data$Type_of_Travel, levels = c("Personal Travel", "Business travel"))
data$Class = factor(data$Class, levels = c("Business", "Eco Plus", "Eco"))
data$satisfaction = factor(data$satisfaction, levels = c("neutral or dissatisfied", "satisfied"))

ratings_fts_names = c("Inflight_wifi_service", "Departure_Arrival_time_convenient", 
  "Ease_of_Online_booking", "Gate_location", "Food_and_drink", "Online_boarding", 
  "Seat_comfort", "Inflight_entertainment", "On_board_service", "Leg_room_service", 
  "Baggage_handling", "Checkin_service", "Inflight_service", "Cleanliness", "On_board_service")

for (col in ratings_fts_names) {
  data[[col]] = factor(data[[col]], levels = c(0:5))
}

```

# Handling na values

In this section, we analyze the dataset to identify variables with missing values, particularly focusing on the "Arrival_Delay_in_Minutes" variable. We calculate the proportion of missing values for this variable and subsequently remove the examples or rows with missing values from the dataset.

```{r}
# list features with na values
prop.table(colSums(is.na(data)))
```

To determine the proportion of missing values for the "Arrival_Delay_in_Minutes" variable, we can count the number of instances where this variable has missing values (commonly denoted as "NaN" or "NA") and divide it by the total number of examples in the dataset. This will give us the proportion of missing values for the "Arrival_Delay_in_Minutes" variable.

```{r}
# Arrival_Delay_in_Minutes has na values, proportion of na values
prop.table(table(is.na(data$Arrival_Delay_in_Minutes)))
```
Indeed, since the proportion of missing values for the "Arrival_Delay_in_Minutes" variable is very low (less than 3% of the entire dataset), it is reasonable to proceed with dropping these missing values from the dataset. 
```{r}
# na values are only 0.03% of the data -> drop na values
data = data %>% drop_na(Arrival_Delay_in_Minutes)
```

# Outliers

In this section, box plots are created for each numeric variable present in the dataset. Box plots are a powerful visualization tool used to identify the presence of outliers in the data. For each numeric variable, the box plot displays a box that represents the interquartile range (IQR), with the median indicated by a line inside the box. The "whiskers" extending from the box show the range of the data, and any data points beyond the whiskers are considered potential outliers.

By examining the box plots for each numeric variable, we can visually identify any data points that lie far outside the typical range of the data, indicating potential outliers. Outliers can significantly impact statistical analyses, so detecting and handling them appropriately is crucial for ensuring the integrity of the dataset and the accuracy of subsequent analyses and modeling.

```{r}

# plot boxplot of each numeric variable excluding ratings features
plots = list()
for (col in names(data)[sapply(data, is.numeric)]) {
  if (col %in% ratings_fts_names) {
    next
  }
  plot = ggplot(data, aes(x = .data[[col]])) +
  geom_boxplot() +
  labs(title = col, x = col, y = "Count") 
  plots[[col]] = plot
}

grid.arrange(grobs = plots, ncol = 2)
```
We can see that there are outliers in Departure_Delay_in_Minutes, Arrival_Delay_in_Minutes and Flight_Distance.
Considering the presence of both near-zero and very large values in the dataset, alternative distributions like the log-normal distribution may be more appropriate for modeling the "Departure_Delay_in_Minutes" and "Arrival_Delay_in_Minutes" variables, as they can better capture the variability in delay times.

# Visualization

In this section, histograms are used to visualize the distribution of the variables in the dataset, starting with the nominal features. By creating histograms for the nominal features, we can gain insights into the distribution of categories within each feature.

Upon visualizing the nominal features, it becomes apparent that some features exhibit heavily unbalanced distributions. This means that certain categories within these features have significantly higher frequencies compared to others. The presence of such imbalanced distributions could have implications for analysis and modeling, as it may lead to biased results or difficulties in predicting less frequent categories accurately.

```{r fig.height=8, fig.width=8}
# plot distribution of categorical variables
plots = list()
for (col in names(data)[sapply(data, is.factor)]) {
  if (col %in% ratings_fts_names) {
    next
  }
  plot = ggplot(data, aes(x = .data[[col]], fill = .data[[col]])) +
  geom_bar() +
  labs(title = paste("Histogram of", col), x = col, y = "Count") +
  guides(fill = FALSE)

  plots[[col]] = plot
}

grid.arrange(grobs = plots, ncol = 2)
```
From the analysis of the nominal features, we can observe the following regarding their balance:

1. Gender: The "Gender" feature is almost perfectly balanced, meaning that there is a relatively equal representation of both genders in the dataset.

2. Satisfaction: The target feature appears to be imbalanced, with fewer instances of "satisfied" compared to the other class ("dissatisfied"). This imbalance could potentially impact the model's performance, and we need to handle it appropriately during the modeling process.

3. Type of Travel: The "Type of Travel" feature shows an imbalance, with more instances of "business travel" compared to "personal travel."

4. Class: The "Class" feature also exhibits imbalance, with "business" and "eco" classes having relatively balanced representations, while the "Eco Plus" class is underrepresented.

5. Customer Type: The "Customer Type" feature shows an imbalance, with a higher number of "loyal customer" instances compared to "disloyal customer."

When dealing with imbalanced data, we need to take specific measures during model training and evaluation to ensure that the model performs well and doesn't exhibit bias towards the majority class. 
Appropriate techniques such as resampling, using different evaluation metrics or employing specialized algorithms can help address the imbalance and lead to a more accurate and fair predictive model.

Now we plot the distribution of ratings features.

```{r fig.height=18, fig.width=12}
# plot distribution of ratings features
plots = list()
my_palette <- c("#1f78b4", "#33a02c", "#e31a1c", "#ff7f00", "#6a3d9a", "#b15928")

for (col in names(data)[sapply(data, is.factor)]) {
  if (!col %in% ratings_fts_names) {
    next
  }
  plot <- ggplot(data, aes(x = .data[[col]], fill = factor(.data[[col]]))) +
    geom_bar() +
    geom_text(stat = 'count', aes(label = after_stat(count))) +  
    labs(title = paste("Histogram of ", col), x = col, y = "Count") +
    scale_fill_manual(values = my_palette) +
    guides(fill = FALSE)

  plots[[col]] <- plot
}
grid.arrange(grobs = plots, ncol = 3)
```
Based on the graphs showing the histograms of the ratings, we can observe that the majority of them tend to fall between 3 and 4. This conclusion is drawn from the visual representation of the data, where the histogram bars are higher in the range of 3 to 4, indicating a higher frequency of ratings in that range.

```{r}
# compute the mean value of all the ratings
ratings_data = data[, c(ratings_fts_names)]
ratings_data <- apply(ratings_data, 2, as.numeric)
ratings_mean = colMeans(ratings_data)
ratings_mean
```


This section presents histograms to visualize the distribution of numeric variables in the dataset. The histograms show that:
1. The age distribution has two main peaks, one at around 25 and another at around 30-35.
2. The flight distance distribution can be represented by a log-normal distribution, with a peak at around 500 miles.
3. The departure delay and arrival delay distributions are very similar, and both show a significant number of outliers.

The histograms provide a useful overview of the distribution of the numeric variables in the dataset. This information can be used to identify potential outliers, and to choose appropriate statistical methods for analyzing the data.
Here are some additional details that could be included in the rephrased text:

1. The age distribution is bimodal, which means that it has two distinct peaks. This could be due to a number of factors, such as the airline's target customer base, or the typical age of people who travel by air.
2. The flight distance distribution is log-normal, which means that it is skewed to the right. This is likely due to the fact that there are a few very long flights, which skew the distribution.
3. The departure delay and arrival delay distributions are very similar, which suggests that they are caused by the same factors. These factors could include weather conditions, air traffic control delays, or mechanical problems with the aircraft.

```{r fig.width=8}
# plot distribution and density of numeric variables excluding ratings features
plots = list()
for (col in names(data)[sapply(data, is.numeric)]) {
  if (col %in% ratings_fts_names) {
    next
  }
  plot = ggplot(data, aes(x = .data[[col]])) +
  geom_histogram(aes(y = after_stat(density)), bins = 30, alpha = 0.5) +
  geom_density(alpha = 0.2, fill = "red") +
  labs(title = paste("Histogram of", col), x = col, y = "Count") 

  plots[[col]] = plot
}

grid.arrange(grobs = plots, ncol = 2)
```

# Visualization vs satisfaction

The observations from the graph analysis provide valuable insights into how different nominal features relate to passenger satisfaction:
1. Gender: both males and females appear to have similar distributions in terms of satisfaction, indicating that gender may not be a strong predictor of passenger satisfaction. The distributions closely resemble the overall distribution of the satisfaction feature.
2. Customer type: the graph suggests that "disloyal customers" are more likely to be unsatisfied or neutral compared to "loyal customers." This indicates that customer loyalty may play a role in passenger satisfaction, with loyal customers tending to be more satisfied.
3. Type of travel: The graph indicates that "personal travelers" are more likely to be unsatisfied compared to "business travelers." Conversely, "business travelers" tend to have a higher proportion of satisfied passengers. This finding suggests that the purpose of travel may have an influence on passenger satisfaction.
4. Class: The graph shows that "business class" passengers are more satisfied than unsatisfied, whereas "eco" and "eco plus" passengers tend to have a higher proportion of unsatisfied passengers. This suggests that the class of service provided by the airline may be a significant factor affecting passenger satisfaction.

```{r fig.width=10}
# plots categorical variables vs satisfaction
plots = list()
for (col in names(data)[sapply(data, is.factor)]) {
  if (col == "satisfaction" || col %in% ratings_fts_names) {
    next
  }
  plot = ggplot(data, aes(x = satisfaction, fill = .data[[col]])) +
  theme_minimal() +
  geom_bar(position = "dodge") +
  labs(title = paste("Histogram of Satisfaction by", col), x = "Satisfaction", y = "Count")

  plots[[col]] = plot
  
}

grid.arrange(grobs = plots, ncol = 2)
```

Based on the observed distribution of the ratings, we can draw the following conclusion:
1. For most of the ratings, the mean value for unsatisfied/neutral consumers is around 3, except for "Inflight Service" and "Baggage Handling." 
```{r}
# calculate the mean of the ratings of unsatisfied/neutral consumers
ratings_data = data[data$satisfaction == "neutral or dissatisfied", c(ratings_fts_names)]
ratings_data <- apply(ratings_data, 2, as.numeric)
ratings_mean = colMeans(ratings_data)
ratings_mean
```
2. For most of the ratings given by satisfied consumers, the mean value is around 4. However, it's important to note that we cannot generalize from this information alone. 
```{r}
# calculate the mean of the ratings of unsatisfied/neutral consumers
ratings_data = data[data$satisfaction == "satisfied", c(ratings_fts_names)]
ratings_data <- apply(ratings_data, 2, as.numeric)
ratings_mean = colMeans(ratings_data)
ratings_mean
```

```{r fig.height=22, fig.width=10}
# plots ratings features vs satisfaction
plots = list()
for (col in names(data)[sapply(data, is.factor)]) {
  if (!col %in% ratings_fts_names) {
    next
  }
  plot = ggplot(data, aes(x = .data[[col]], fill = satisfaction)) +
  theme_minimal() +
  geom_bar(position = "dodge") +
  labs(title = paste("Histogram of Satisfaction by", col), x = "Satisfaction", y = "Count")

  plots[[col]] = plot  
}

grid.arrange(grobs = plots, ncol = 2)
```

Based on the boxplots and the information provided, we can make the following observations about the distributions of the numerical features:

1. Age: the boxplot for "Age" suggests that the distribution is approximately normal. Furthermore, it appears that neutral or dissatisfied customers tend to be slightly younger on average compared to satisfied customers.

2. Flight Distance: the boxplot does not exhibit a normal distribution. Instead, it appears to have a right-skewed distribution. This is evident from the longer whisker on the right side, indicating that there are some outliers with larger flight distances.

3. Departure Delay in Minutes: the boxplot for "Departure Delay in Minutes" also shows a right-skewed distribution. The majority of the data appears to be concentrated towards the lower values, with a lot of outliers representing longer departure delays.

4. Arrival Delay in Minutes: similar to the "Departure Delay in Minutes," the boxplot for "Arrival Delay in Minutes" exhibits a right-skewed distribution. The bulk of the data is clustered towards the lower values, with a lot of outliers indicating longer arrival delays.

Based on these observations, it's essential to consider the appropriate data transformations or use different distribution models when working with "Flight Distance," "Departure Delay in Minutes," and "Arrival Delay in Minutes." For example, logarithmic transformations may be suitable to handle the skewed nature of these variables in statistical analyses and modeling tasks.
```{r fig.height=7, fig.width=10}
# plots numeric variables vs satisfaction excluding ratings features with histograms of different colors for each satisfaction level
plots = list()
for (col in names(data)[sapply(data, is.numeric)]) {
  if (col %in% ratings_fts_names) {
    next
  }
  plot = ggplot(data, aes(x = .data[[col]], fill = satisfaction, group = satisfaction)) +
    theme_minimal() +
    geom_histogram(alpha = 0.5, bins = 30) +
    labs(title = paste("Histogram of", col), x = col, y = "Count") 

  plots[[col]] = plot
}

grid.arrange(grobs = plots, ncol = 2)

```

# Data balance

This section calculates the proportion of satisfied and dissatisfied
customers in the dataset.

```{r}
prop.table(table(data$satisfaction))

```

# Feature engineering

```{r}
# add new feature
ratings_data = data[, c(ratings_fts_names)]
ratings_data <- apply(ratings_data, 2, as.numeric)
# 1. ratings mean
data$ratings_mean = rowMeans(ratings_data)

# 2. onboard rating mean
onboard_features = c("Inflight_wifi_service", "Food_and_drink", 
  "Seat_comfort", "Inflight_entertainment", "On_board_service", "Leg_room_service", 
  "Baggage_handling", "Inflight_service", "Cleanliness")

data$onboard_rating_mean = rowMeans(ratings_data[, onboard_features])

```

# Convert categorical to numerical

This section converts the categorical variables to numeric
representation for further analysis.

```{r}
# gender_map = c("Male" = 0, "Female" = 1)
# data$Gender = gender_map[as.numeric(data$Gender)]

# customer_type_map = c("Loyal Customer" = 0, "disloyal Customer" = 1)
# data$Customer_Type = customer_type_map[as.numeric(data$Customer_Type)]

# type_of_travel_map = c("Personal Travel" = 0, "Business travel" = 1)
# data$Type_of_Travel = type_of_travel_map[as.numeric(data$Type_of_Travel)]

# class_map = c("Business" = 0, "Eco" = 1, "Eco Plus" = 2)

# satisfaction_map = c("neutral or dissatisfied" = 0, "satisfied" = 1)
# data$satisfaction = satisfaction_map[as.numeric(data$satisfaction)]
```

# Train test split

This section splits the data into training and testing sets, prints the
proportion of satisfied and dissatisfied customers in each set, and
saves the true values of the target variable for the test set.

```{r}
set.seed(123)
train_index = sample(1:nrow(data), 0.8*nrow(data))
# 80% of data is used for training
train = data[train_index,]
# 20% of data is used for testing
test = data[-train_index,]

# merge train and test data
data = rbind(train, test)
# save on cvs
# write.csv(data, "data.csv")

# save true values of test satisfaction column
test_true = test$satisfaction

# drop satisfaction column from test data
test = test %>% select(-satisfaction)

# print proportion of satisfied and dissatisfied customers in train and test data
prop.table(table(train$satisfaction))
prop.table(table(test_true))
```
```{r}
## Correlation matrix for numerical features

ds_cor1 <- cor(subset(data,select = c(Age, Flight_Distance,Departure_Delay_in_Minutes,Arrival_Delay_in_Minutes)))
summary(ds_cor1)
options(repr.plot.width = 14, repr.plot.height = 8)
corrplot(ds_cor1, na.label = " ", method="color", tl.col = "black", tl.cex = 1)


## Correlation matrix for ordinal features

ds_cor2 <- cor(subset(data, select = c(Inflight_wifi_service, Departure_Arrival_time_convenient, Ease_of_Online_booking, Gate_location, Food_and_drink, Online_boarding, Seat_comfort, Inflight_entertainment, On_board_service, Leg_room_service, Baggage_handling, Checkin_service, Inflight_service,Cleanliness)))
summary(ds_cor2)
options(repr.plot.width = 14, repr.plot.height = 8)
corrplot(ds_cor2, na.label=" ", tl.cex=1, tl.col="black", method="color")

```
# Relation between Arrival_Delay_in_Minutes and Departure_Delay_in_Minutes (linear)

This section explores the partial correlation matrix and identifies
variables with high correlations with the target variable
(satisfaction). It also creates a bar plot to show the correlations.

```{r}

#CORRELATION MATRIX again but now we are interested in partial correlation
#So we look for all the correlations between variables
#We pick the highest, setting a treshold of our choice

#build a dataframe where for each variable we look the partial correlation with all the others
#we pick the highest and we save it in a dataframe
#we set a treshold of 0



#save the partial correlation matrix result in a dataframe and output a file for further analysis

# do the partial correlation only for numerical variables
#partial_corr = correlation(data[,sapply(data, is.numeric)], partial=TRUE, method = "spearman", use = "pairwise.complete.obs", verbose = TRUE)
#write.csv(partial_corr, file = "partial_corr.csv")

partial_correlations = read.csv("partial_corr.csv", header = TRUE, sep = ",")


head(partial_correlations)
#make the first column the row names

rownames(partial_correlations) = partial_correlations[,1]

# delete the first column
partial_correlations = partial_correlations[,-1]

#round the values
partial_correlations_rounded = round(partial_correlations, digits = 3)

# Remove the first column (variable names) to keep only numeric values
correlation_matrix_numeric <- partial_correlations[, -1]

# Convert the data to a matrix
correlation_matrix_matrix <- as.matrix(partial_correlations)
correlation_matrix_matrix

options(repr.plot.width = 14, repr.plot.height = 8)
corrplot(correlation_matrix_matrix, na.label = " ", method="color", tl.col = "black", tl.cex = 1)





# Initialize empty data frame with 0 rows
# We need it to create a data frame with the results and
# so to show better the correlations.
df <- data.frame(variable1 = character(),
                 variable2 = character(),
                 value = numeric(),
                 stringsAsFactors = FALSE)

# Loop over rows and columns of matrix
for (i in 1:nrow(partial_correlations_rounded)) {
  for (j in 1:ncol(partial_correlations_rounded)) {
    # Check if value meets criterion
    if ((partial_correlations_rounded[i,j] > 0.300 | partial_correlations_rounded[i,j] < -0.300)& i != j) {
      # Add row to data frame
      df <- rbind(df, data.frame(variable1 = rownames(partial_correlations_rounded)[i],
                                 variable2 = colnames(partial_correlations_rounded)[j],
                                 value = partial_correlations_rounded[i,j],
                                 stringsAsFactors = FALSE))
    }
  }
}


# Group the data frame by variable1 and extract top 3 values for each group
df_top3 <- df %>% group_by(variable1) %>% top_n(4, value) %>% ungroup()

#order by variable1
df_top3 <- df_top3[order(df_top3$variable1),]


#delete duplicates in the dataframe if variable1 is equal to variable2
df_top3 <- df_top3[!(df_top3$variable1 == df_top3$variable2),]

print(df_top3, n = nrow(df_top3))
#save on cvs
# write.csv(df_top3, file = "df_top3.csv")
```

```{r}
# standardize Arrival_Delay_in_Minutes and Departure_Delay_in_Minutes
arrival_std = scale(data$Arrival_Delay_in_Minutes)
departure_std = scale(data$Departure_Delay_in_Minutes)
# scatter plot of Arrival_Delay_in_Minutes and Departure_Delay_in_Minutes 
plot(arrival_std, departure_std, xlab = "Arrival_Delay_in_Minutes", ylab = "Departure_Delay_in_Minutes")
# plot line y = x
abline(0, 1, col = "red")
```


